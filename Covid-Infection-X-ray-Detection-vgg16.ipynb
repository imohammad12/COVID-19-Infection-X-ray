{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "STAT946-DataChallenge-one-vgg16.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "qjKPvJxYHrbP",
        "Gn9kNfaDP3Yx",
        "FjQi_gw0XB69"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3e4d428af8a14f1d8265ecb6beff37a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d59f838596854e549626cb299c6557ab",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_129ef447b9c5457ea5883726132123d5",
              "IPY_MODEL_e3141c3b2f8a450184f255103e3a8d9b"
            ]
          }
        },
        "d59f838596854e549626cb299c6557ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "129ef447b9c5457ea5883726132123d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0bbb7a55e3b640bb95296eecc5b1a81b",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 553507836,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 553507836,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8fc5fe3f35914c4c8a2b6c576e8a4fff"
          }
        },
        "e3141c3b2f8a450184f255103e3a8d9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_19ceca9a316a487a91809eb744c701fc",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 528M/528M [18:00&lt;00:00, 512kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_05f216e144a34984aa6acc91685c5ad0"
          }
        },
        "0bbb7a55e3b640bb95296eecc5b1a81b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8fc5fe3f35914c4c8a2b6c576e8a4fff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "19ceca9a316a487a91809eb744c701fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "05f216e144a34984aa6acc91685c5ad0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tHaeIlnBKynp",
        "outputId": "1eb6bf41-6919-4f87-dfd4-e630e126e56a"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/content/gdrive/MyDrive/\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n",
            "/content/gdrive/MyDrive/STAT-946/TestingCode\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PCacpPk2l7JM"
      },
      "source": [
        "%matplotlib inline\n",
        "# %config InlineBackend.figure_format = \"retina\"\n",
        "from __future__ import print_function\n",
        "from __future__ import division\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "from torch.utils.data import WeightedRandomSampler\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "import helper\n",
        "import shutil\n",
        "import pandas as pd\n",
        "import random\n",
        "import os\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-l49Os2XyqSv"
      },
      "source": [
        "\n",
        "\n",
        "> In this project I have used vgg16 (the version having batchnorm) for prediciting infection to COVID-19 based on chest X-ray images. \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjKPvJxYHrbP"
      },
      "source": [
        "# Prepairing the Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZKBztWBzivb"
      },
      "source": [
        "> **Create a new folder and then place stat946winter2021.zip file in it. Go to the new folder that stat946winter2021.zip is in.**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4eJjXZVRh-r0"
      },
      "source": [
        "def DownloadData():\n",
        "  # load your coookies from kaggle.com to download the dataset\n",
        "  !wget -x --load-cookies kaggle.com_cookies.txt \"https://www.kaggle.com/c/25588/download-all\" -O stat946winter2021.zip\n",
        "\n",
        "def PrepairFolders():\n",
        "\n",
        "  # Creating the data root folder\n",
        "  os.makedirs(data_root)\n",
        "\n",
        "  %cd $data_root\n",
        "\n",
        "  # Moving the stat946winter2021.zip to data root folder\n",
        "  ! mv ../stat946winter2021.zip ./\n",
        "\n",
        "  \n",
        "  !unzip stat946winter2021.zip\n",
        "\n",
        "  # ! rm -rf train/0\n",
        "  # ! rm -rf train/1\n",
        "  # ! rm -rf validation/1\n",
        "  # ! rm -rf validation/0\n",
        "  try:\n",
        "    os.makedirs(dest_validation_neg)\n",
        "    os.makedirs(dest_validation_pos)\n",
        "    os.makedirs(dest_train_neg)\n",
        "    os.makedirs(dest_train_pos)\n",
        "  except:\n",
        "    print(\"file already exists\")\n",
        "\n",
        "\n",
        "def PrepairData():\n",
        "\n",
        "  %cd $data_root\n",
        "  df = pd.read_csv('train_labels.csv')\n",
        "\n",
        "  # Split Train to Validation and Train\n",
        "  Test_Train_ratio = .1\n",
        "  ValidationIndex = random.sample(range(0, len(df)), int(len(df) * Test_Train_ratio))\n",
        "\n",
        "  ImagesDir = os.path.join(data_root, \"train/train\")\n",
        "\n",
        "  for index, filename in enumerate(df['File']):\n",
        "    label = df.iloc[index][1]\n",
        "    print(\"image name : {}, label :{}\".format(filename, label))\n",
        "    source = os.path.join(ImagesDir, filename)\n",
        "    \n",
        "    # Positive Case\n",
        "    if label: \n",
        "\n",
        "      # Image in validation set\n",
        "      if index in ValidationIndex: \n",
        "        shutil.move(source, dest_validation_pos)\n",
        "\n",
        "      # Image in training set\n",
        "      else:\n",
        "        shutil.move(source, dest_train_pos)\n",
        "    \n",
        "    # Negative Case\n",
        "    else: \n",
        "      \n",
        "      # Image in validation set\n",
        "      if index in ValidationIndex: \n",
        "        shutil.move(source, dest_validation_neg)\n",
        "\n",
        "      # Image in training set\n",
        "      else: \n",
        "        shutil.move(source, dest_train_neg)\n",
        "\n",
        "  ! rm -rf train/train\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j2TT0B_gyxqA"
      },
      "source": [
        "> Run the following cell code to prepair the data and create needed folders. \n",
        "\n",
        "> Run this cell just once"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMjJJwLjkCOh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b834e87b-f79f-4445-8fca-ee2cd87aef04"
      },
      "source": [
        "current_floder = %pwd\n",
        "data_root = os.path.join(current_floder, \"data/\")\n",
        "\n",
        "\n",
        "dest_validation_neg = os.path.join(data_root, \"val/0\")\n",
        "dest_validation_pos = os.path.join(data_root, \"val/1\")\n",
        "dest_train_neg = os.path.join(data_root, \"train/0\")\n",
        "dest_train_pos = os.path.join(data_root, \"train/1\")\n",
        "\n",
        "model_name = 'vgg16'\n",
        "num_classes = 2\n",
        "batch_size = 8\n",
        "num_epochs = 15\n",
        "\n",
        "# Flag for feature extracting. When False, we finetune the whole model,\n",
        "#   when True we only update the reshaped layer params\n",
        "feature_extract = True\n",
        "\n",
        "\n",
        "print(data_root)\n",
        "\n",
        "# Here we donwload and prepair data for using ImageFolder module in pytroch\n",
        "# DownloadData() # If you have put the stat946winter2021.zip in the current folder do not use this function.\n",
        "PrepairFolders()\n",
        "PrepairData()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/MyDrive/STAT-946/TestingCode/data/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ninlw9iM-mLO"
      },
      "source": [
        "After running this cell the data should be splitted into the **train** and **val** folders. Data in each of these folders is also splitted based on positive and negative cases."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LWotr_-BiGzf"
      },
      "source": [
        "# Helper Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gn9kNfaDP3Yx"
      },
      "source": [
        "## Training Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MgzDLeHQAfi"
      },
      "source": [
        "def train_model(model, dataloaders, criterion, optimizer, model_name, num_epochs=25):\n",
        "    since = time.time()\n",
        "\n",
        "    val_acc_history = []\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    \n",
        "                    # Get model outputs and calculate loss\n",
        "                    outputs = model(inputs)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
        "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
        "\n",
        "            print('{} Loss: {:.5f} Acc: {:.5f}'.format(phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "                # Save the model if this model is better than the previously saved models\n",
        "                save_model(model, float(best_acc), model_name)\n",
        "            if phase == 'val':\n",
        "                val_acc_history.append(epoch_acc)\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model, val_acc_history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bVliXQoDQg1B"
      },
      "source": [
        "## Setting Parameters requires_grad"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8W22q_QQbx5"
      },
      "source": [
        "# Setting requires_grad to Flase if the model is in feature extracting mode\n",
        "# Else model is in fine tunning and the requires_grad is set to True\n",
        "\n",
        "def set_parameter_requires_grad(model, feature_extracting):\n",
        "    if feature_extracting:\n",
        "        for param in model.parameters():\n",
        "            param.requires_grad = False\n",
        "    else:\n",
        "        for param in model.parameters():\n",
        "            param.requires_grad = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dzuVJ7JbSQXf"
      },
      "source": [
        "## Initializing The Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NDNP-WhKSdCp"
      },
      "source": [
        "# We only initialize the last layer of the model. Other weights are used as the pretrained model\n",
        "# Based on feature_extract we set requires_grad of weights.\n",
        "\n",
        "def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n",
        "    if model_name == \"vgg11\":\n",
        "        model_ft = models.vgg11_bn(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.classifier[6].in_features\n",
        "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == 'vgg16':\n",
        "        model_ft = models.vgg16_bn(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.classifier[6].in_features\n",
        "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"alexnet\":\n",
        "        model_ft = models.alexnet(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.classifier[6].in_features\n",
        "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
        "        input_size = 224\n",
        "  \n",
        "    return model_ft, input_size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OAHoexDmTUix"
      },
      "source": [
        "## Saving The Best Model Weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NodzSrwNrRQ4"
      },
      "source": [
        "# Saving the model weights\n",
        "# We save the model that has the best accuracy.\n",
        "# Other saved weights will be removed if current model has better accuracy.\n",
        "\n",
        "def save_model(model, acc, model_name):\n",
        "  \n",
        "  %cd $data_root\n",
        "  %cd ..\n",
        "  main_path = %pwd\n",
        "\n",
        "  model_path = os.path.join(main_path, 'BestModel/')\n",
        "  if os.path.isdir(model_path) == False:\n",
        "    os.makedirs(model_path)\n",
        "\n",
        "  %cd $model_path\n",
        "\n",
        "  # Check if the current model is better than saved models or not\n",
        "  is_best = True\n",
        "\n",
        "  # Get a list of model names\n",
        "  saved_models = os.listdir(\"./\")\n",
        "\n",
        "  # Search for the best saved model with the same architecture\n",
        "  for m in saved_models:\n",
        "    saved_acc = m.split('_')[2]\n",
        "    if float(saved_acc) < acc and m.split('_')[-1] == model_name:\n",
        "      os.remove(m)\n",
        "    elif float(saved_acc) >= acc and m.split('_')[-1] == model_name:\n",
        "      is_best = False\n",
        "\n",
        "  # best_acc = float(torch.tensor(hist).sort()[0][-1])\n",
        "  if is_best:\n",
        "    torch.save(model.state_dict(), 'model_acc_' + str(acc) + '_' + model_name)\n",
        "    # Path('model_acc_' + str(acc) + '_' + model_name).touch()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CU85DjARbENZ"
      },
      "source": [
        "## Loading The Best Model Weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5etj5UZ2l45"
      },
      "source": [
        "def load_model(model_ft):\n",
        "\n",
        "  # Loading the best model from BestModel folder\n",
        "\n",
        "  %cd $data_root\n",
        "  %cd ..\n",
        "  main_path = %pwd\n",
        "\n",
        "  model_path = os.path.join(main_path, 'BestModel/')\n",
        "  \n",
        "  if os.path.isdir(model_path) == False:\n",
        "    os.makedirs(model_path)\n",
        "  \n",
        "  %cd $model_path\n",
        "\n",
        "  # Downloading the weight that has an 98.3 % accuracy\n",
        "  ! wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1-mRMr_MB1S71WwDgIBaM6JYCpSmTPn5N' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1-mRMr_MB1S71WwDgIBaM6JYCpSmTPn5N\" -O model_acc_0.9836173001310_vgg16 && rm -rf /tmp/cookies.txt\n",
        "\n",
        "  # Get a list of model names\n",
        "  models = os.listdir(\"./\")\n",
        "  best_acc = 0\n",
        "  best_model = \"\"\n",
        "\n",
        "  # Search for the best saved model\n",
        "  for m in models:\n",
        "    acc = m.split('_')[2]\n",
        "    if float(acc) > best_acc:\n",
        "      best_model = m\n",
        "\n",
        "  \n",
        "  print(\"model {} is loaded\". format(best_model))\n",
        "  model_ft.load_state_dict(torch.load(best_model))\n",
        "  model_ft.eval()\n",
        "  \n",
        "  return model_ft"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okWInVmkTwA_"
      },
      "source": [
        "## Weighted Sampler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kW1513oSTvN3"
      },
      "source": [
        "# Creating a Weighted Sampler object\n",
        "def weight_sampler(image_dataset):  \n",
        "  targets = np.array(image_dataset.targets)\n",
        "  class_sample_count = np.array([len(np.where(targets == t)[0]) for t in np.unique(targets)])\n",
        "  weight = 1. / class_sample_count\n",
        "  print(class_sample_count)\n",
        "  samples_weight = np.array([weight[t] for t in targets])\n",
        "\n",
        "  samples_weight = torch.from_numpy(samples_weight)\n",
        "  samples_weigth = samples_weight.double()\n",
        "  sampler = WeightedRandomSampler(samples_weight, len(samples_weight))\n",
        "\n",
        "  return sampler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3MB_l2pcjN6-"
      },
      "source": [
        "# Initializing the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "3e4d428af8a14f1d8265ecb6beff37a3",
            "d59f838596854e549626cb299c6557ab",
            "129ef447b9c5457ea5883726132123d5",
            "e3141c3b2f8a450184f255103e3a8d9b",
            "0bbb7a55e3b640bb95296eecc5b1a81b",
            "8fc5fe3f35914c4c8a2b6c576e8a4fff",
            "19ceca9a316a487a91809eb744c701fc",
            "05f216e144a34984aa6acc91685c5ad0"
          ]
        },
        "id": "MwNB8YA1yOku",
        "outputId": "6cd57452-0a13-4f48-d498-2b9d8b924048"
      },
      "source": [
        "model_ft, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=True)\n",
        "\n",
        "# Prinitng the altered pretrained model\n",
        "print(model_ft)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg16_bn-6c64b313.pth\" to /root/.cache/torch/hub/checkpoints/vgg16_bn-6c64b313.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3e4d428af8a14f1d8265ecb6beff37a3",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=553507836.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Dropout(p=0.5, inplace=False)\n",
            "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): Dropout(p=0.5, inplace=False)\n",
            "    (6): Linear(in_features=4096, out_features=2, bias=True)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8lUDW2qLqxK_"
      },
      "source": [
        "#Loading Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cBVJAHIpq2o4",
        "outputId": "25d684fd-b798-494a-8042-7e3db999ac28"
      },
      "source": [
        "# Data augmentation and normalization for training\n",
        "# Just normalization for validation\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomResizedCrop(input_size),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize(input_size),\n",
        "        transforms.CenterCrop(input_size),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}\n",
        "\n",
        "print(\"Initializing Datasets and Dataloaders...\")\n",
        "\n",
        "# Create training and validation datasets\n",
        "image_datasets = {x: datasets.ImageFolder(os.path.join(data_root, x), data_transforms[x]) for x in ['train', 'val']}\n",
        "# Create training and validation dataloaders\n",
        "\n",
        "# Trying to handle the unbalanced data using pytorch samplers\n",
        "# Generating a weighted sampler\n",
        "w_sampler = weight_sampler(image_datasets['train'])\n",
        "\n",
        "dataloaders_dict = {}\n",
        "for x in ['train', 'val']:\n",
        "  if x == 'train':\n",
        "    dataloaders_dict[x] = torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=False, sampler=w_sampler, num_workers=4)\n",
        "  else:\n",
        "    dataloaders_dict[x] = torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True, num_workers=4)\n",
        "\n",
        "# Detect if we have a GPU available\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initializing Datasets and Dataloaders...\n",
            "[12335  1403]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0DT2zCFCoAT"
      },
      "source": [
        "# Creating Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9jI2_PLNCvK6"
      },
      "source": [
        "def set_optimizer(model_ft):\n",
        "    # Send the model to GPU\n",
        "    model_ft = model_ft.to(device)\n",
        "\n",
        "    # Gather the parameters to be optimized/updated in this run.\n",
        "    params_to_update = model_ft.parameters()\n",
        "    print(\"Params to learn:\")\n",
        "    if feature_extract:\n",
        "        params_to_update = []\n",
        "        for name,param in model_ft.named_parameters():\n",
        "            if param.requires_grad == True:\n",
        "                params_to_update.append(param)\n",
        "                print(\"\\t\",name)\n",
        "    else:\n",
        "        for name,param in model_ft.named_parameters():\n",
        "            if param.requires_grad == True:\n",
        "                print(\"\\t\",name)\n",
        "\n",
        "    # Observe that all parameters are being optimized\n",
        "    return optim.SGD(params_to_update, lr=0.001, momentum=0.9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndRJLrO7F_Mp"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJ6wAeGFWV9o"
      },
      "source": [
        "## Setting Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1WXo5yFGWVZH",
        "outputId": "2111a1a3-a7e6-4dcb-e2ae-8ee84bfcac58"
      },
      "source": [
        "# Setup the loss fxn\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer_ft = set_optimizer(model_ft)\n",
        "# Prints the parameters that are going to be updated during gradient decent"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Params to learn:\n",
            "\t classifier.6.weight\n",
            "\t classifier.6.bias\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FjQi_gw0XB69"
      },
      "source": [
        "## Training The Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGh_CUtLGK5Y"
      },
      "source": [
        "\n",
        "# Train only the last layer of the model - other wieths are freezed\n",
        "model_ft, hist = train_model(model_ft, dataloaders_dict, criterion, optimizer_ft, model_name=model_name, num_epochs=num_epochs)\n",
        "\n",
        "# Fine-tunning the whole model after the last layer weights has been updated for some ecpochs \n",
        "feature_extract = False\n",
        "set_parameter_requires_grad(model_ft, feature_extracting=feature_extract)\n",
        "optimizer_ft = set_optimizer(model_ft)\n",
        "\n",
        "num_epochs = 35\n",
        "model_ft, hist = train_model(model_ft, dataloaders_dict, criterion, optimizer_ft, model_name=model_name, num_epochs=num_epochs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MM8r3fqbttm"
      },
      "source": [
        "## Loading Best Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vIVV2d3b5oCv"
      },
      "source": [
        "Instead of Training you can Load the weights. \n",
        "The weights that can reporduce the CSV results that was submited in Kaggle will be downloaded and loaded automatically.\n",
        "\n",
        "The folliwng cell will automaticaly download the weight and move the weight to the BestModel folder (will be created if does not exist). Then loads and returns the best model that exists in this folder.\n",
        "\n",
        "You can also have access to this weight using this link:\n",
        "[Model Accuracy 98.3](https://drive.google.com/file/d/1-mRMr_MB1S71WwDgIBaM6JYCpSmTPn5N/view?usp=sharing)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2wyhfJzgb1Zc",
        "outputId": "8b8f5729-6de3-4956-e61c-e5c9e3f72868"
      },
      "source": [
        "# Loades the best model in the BestModel folder (will be created if does not exist).\n",
        "# Downloads a weight that have an 98.3% accuracy\n",
        "model_ft = load_model(model_ft)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/MyDrive/STAT-946/TestingCode/data\n",
            "/content/gdrive/MyDrive/STAT-946/TestingCode\n",
            "/content/gdrive/MyDrive/STAT-946/TestingCode/BestModel\n",
            "--2021-02-14 20:29:20--  https://docs.google.com/uc?export=download&confirm=CzaI&id=1-mRMr_MB1S71WwDgIBaM6JYCpSmTPn5N\n",
            "Resolving docs.google.com (docs.google.com)... 172.217.12.238, 2607:f8b0:4004:82a::200e\n",
            "Connecting to docs.google.com (docs.google.com)|172.217.12.238|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://doc-10-as-docs.googleusercontent.com/docs/securesc/jdcenaolhaq3vunredsataip4de1047o/6f4dc917310505ibnv4o298d5q45gifp/1613334525000/13043136208596042681/04847398216668824266Z/1-mRMr_MB1S71WwDgIBaM6JYCpSmTPn5N?e=download [following]\n",
            "--2021-02-14 20:29:20--  https://doc-10-as-docs.googleusercontent.com/docs/securesc/jdcenaolhaq3vunredsataip4de1047o/6f4dc917310505ibnv4o298d5q45gifp/1613334525000/13043136208596042681/04847398216668824266Z/1-mRMr_MB1S71WwDgIBaM6JYCpSmTPn5N?e=download\n",
            "Resolving doc-10-as-docs.googleusercontent.com (doc-10-as-docs.googleusercontent.com)... 172.217.12.225, 2607:f8b0:4004:807::2001\n",
            "Connecting to doc-10-as-docs.googleusercontent.com (doc-10-as-docs.googleusercontent.com)|172.217.12.225|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://docs.google.com/nonceSigner?nonce=d6pl5qlt6hejg&continue=https://doc-10-as-docs.googleusercontent.com/docs/securesc/jdcenaolhaq3vunredsataip4de1047o/6f4dc917310505ibnv4o298d5q45gifp/1613334525000/13043136208596042681/04847398216668824266Z/1-mRMr_MB1S71WwDgIBaM6JYCpSmTPn5N?e%3Ddownload&hash=75q0jaqkvve5ikv6j3k2r3iuoebhm64s [following]\n",
            "--2021-02-14 20:29:20--  https://docs.google.com/nonceSigner?nonce=d6pl5qlt6hejg&continue=https://doc-10-as-docs.googleusercontent.com/docs/securesc/jdcenaolhaq3vunredsataip4de1047o/6f4dc917310505ibnv4o298d5q45gifp/1613334525000/13043136208596042681/04847398216668824266Z/1-mRMr_MB1S71WwDgIBaM6JYCpSmTPn5N?e%3Ddownload&hash=75q0jaqkvve5ikv6j3k2r3iuoebhm64s\n",
            "Connecting to docs.google.com (docs.google.com)|172.217.12.238|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://doc-10-as-docs.googleusercontent.com/docs/securesc/jdcenaolhaq3vunredsataip4de1047o/6f4dc917310505ibnv4o298d5q45gifp/1613334525000/13043136208596042681/04847398216668824266Z/1-mRMr_MB1S71WwDgIBaM6JYCpSmTPn5N?e=download&nonce=d6pl5qlt6hejg&user=04847398216668824266Z&hash=tnrsie7bmhnhnmh4r1oikfc6gtk6ebk7 [following]\n",
            "--2021-02-14 20:29:20--  https://doc-10-as-docs.googleusercontent.com/docs/securesc/jdcenaolhaq3vunredsataip4de1047o/6f4dc917310505ibnv4o298d5q45gifp/1613334525000/13043136208596042681/04847398216668824266Z/1-mRMr_MB1S71WwDgIBaM6JYCpSmTPn5N?e=download&nonce=d6pl5qlt6hejg&user=04847398216668824266Z&hash=tnrsie7bmhnhnmh4r1oikfc6gtk6ebk7\n",
            "Connecting to doc-10-as-docs.googleusercontent.com (doc-10-as-docs.googleusercontent.com)|172.217.12.225|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/x-zip]\n",
            "Saving to: ‘model_acc_0.9836173001310_vgg16’\n",
            "\n",
            "model_acc_0.9836173     [               <=>  ] 512.29M  64.2MB/s    in 9.7s    \n",
            "\n",
            "2021-02-14 20:29:30 (52.8 MB/s) - ‘model_acc_0.9836173001310_vgg16’ saved [537175203]\n",
            "\n",
            "model model_acc_0.9836173001310_vgg16 is loaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0u3RXpdS1Zl"
      },
      "source": [
        "# Testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k2TnPsjC-XLA"
      },
      "source": [
        "## Loading The Test Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2DR2Kbc7S2Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2d590a5-4082-45df-a8da-1891e099a37c"
      },
      "source": [
        "%cd $data_root\n",
        "\n",
        "tdf = pd.read_csv('sample_submission.csv')\n",
        "model_ft.eval()\n",
        "\n",
        "test_dataset = datasets.ImageFolder(os.path.join(data_root, 'test'), data_transforms['val'])\n",
        "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/MyDrive/STAT-946/TestingCode/data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tHDP9vCc_leZ"
      },
      "source": [
        "## Testing on Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_ygJPO1cuGl"
      },
      "source": [
        "# Testing the model on Validation dataset\n",
        "\n",
        "model_ft.eval()\n",
        "val_labels = [] # Predicted Lables\n",
        "corr_labels = [] # Correct Label\n",
        "for i, (batch_img, labels) in enumerate(dataloaders_dict['val']):\n",
        "  batch_img = batch_img.to(device)\n",
        "  output = model_ft(batch_img)\n",
        "  \n",
        "  for out in output.cpu().argmax(dim=1).numpy():\n",
        "    val_labels.append(out)\n",
        "  for l in labels.numpy():\n",
        "    corr_labels.append(l)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m6KsyhF9z8OA",
        "outputId": "1c961c1b-afb7-4e5f-e8e2-134429e65dab"
      },
      "source": [
        "# Finding the correct predictions\n",
        "tar = np.array(val_labels) == np.array(corr_labels)\n",
        "\n",
        "# Accurcay on Validation\n",
        "print(\"the model's accuracy on validaiton is: {}\".format(tar.sum()/len(corr_labels)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the model's accuracy on validaiton is: 0.9888597640891219\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKP4CiJG_OJ2"
      },
      "source": [
        "## Testing on Test Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-HsWE5d_N5U"
      },
      "source": [
        "model_ft.eval()\n",
        "test_lables = []\n",
        "\n",
        "for i, (batch_img, labels) in enumerate(test_dataloader):\n",
        "  batch_img = batch_img.to(device)\n",
        "  output = model_ft(batch_img)\n",
        "\n",
        "  # Add the prediction to list of predictions\n",
        "  test_lables.append(output.cpu().argmax(dim=1).numpy()[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSIYSyi0wWbJ"
      },
      "source": [
        "# Obtaining image names\n",
        "test_imgs_names = []\n",
        "for i in range(len(test_dataset)):\n",
        "  test_imgs_names.append(test_dataset.imgs[i][0].split('/')[-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OP7_74QI5zjx",
        "outputId": "2d76b9e0-f986-4dd7-b115-6d6a1b62d1fc"
      },
      "source": [
        "%cd $data_root\n",
        "df = pd.read_csv('train_labels.csv')\n",
        "test_df = pd.read_csv('sample_submission.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/MyDrive/STAT-946/TestingCode/data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8IyYDHPv1PE1"
      },
      "source": [
        "# Updating the data frame file of test data\n",
        "for i, img in enumerate(test_imgs_names):\n",
        "  # Setting the lable of each image based on the model prediction\n",
        "  tdf.loc[tdf['File'] == img , tdf.columns[1]] = str(test_lables[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cR657YHjeIw2"
      },
      "source": [
        "# Saving the new CSV file\n",
        "tdf.to_csv('precidted_lables.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oCkLbsPf_tIW"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    }
  ]
}